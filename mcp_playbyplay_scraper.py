#!/usr/bin/env python3
"""
MCP Playwright Play-by-Play Scraper - WORKING VERSION
Uses MCP Playwright browser tools to extract ESPN play-by-play data
Adds 4-column structure to existing working columns (not replacing)
"""

import psycopg2
from psycopg2.extras import RealDictCursor
import re
import json
from datetime import datetime
from typing import Dict, List, Optional

class MCPPlayByPlayScraper:
    def __init__(self):
        self.conn = None
        self.connect_to_database()
        self.processed_games = 0
        self.successful_games = 0
        self.failed_games = 0
        
        print("ğŸˆ MCP Playwright Play-by-Play Scraper initialized")
        print("âœ… Uses MCP Playwright browser tools (not ChromeDriver)")
        print("âœ… Adds 4-column structure to existing working columns")
        print("âœ… Handles ESPN game_id relationships correctly")
        
    def connect_to_database(self):
        """Connect to PostgreSQL database"""
        try:
            self.conn = psycopg2.connect(
                host="192.168.1.23",
                database="football_tracker",
                user="postgres", 
                password="korn5676",
                port=5432
            )
            print("âœ… Database connected")
        except Exception as e:
            print(f"âŒ Database connection failed: {e}")
            raise
            
    def get_all_games(self):
        """Get all games from database"""
        cursor = self.conn.cursor(cursor_factory=RealDictCursor)
        cursor.execute("""
            SELECT g.id as db_id, g.game_id as espn_game_id, g.date, g.season, g.week,
                   t1.abbreviation as home_team, t2.abbreviation as away_team
            FROM games g
            JOIN teams t1 ON g.home_team_id = t1.id
            JOIN teams t2 ON g.away_team_id = t2.id
            WHERE g.game_id IS NOT NULL
            ORDER BY g.date DESC
        """)
        games = cursor.fetchall()
        cursor.close()
        return games
    
    def parse_4_line_play_structure(self, play_data_json):
        """Parse 4-line play structure from MCP browser extraction"""
        try:
            plays_data = []
            
            if not play_data_json or 'plays' not in play_data_json:
                return []
                
            for i, play_info in enumerate(play_data_json['plays']):
                if 'texts' not in play_info or len(play_info['texts']) < 3:
                    continue
                    
                texts = play_info['texts']
                
                # Look for time-quarter pattern to identify play cards
                time_quarter_line = None
                time_quarter_index = -1
                
                for j, text in enumerate(texts):
                    if re.match(r'\d{1,2}:\d{2}\s*-\s*(1st|2nd|3rd|4th|OT)', text):
                        time_quarter_line = text
                        time_quarter_index = j
                        break
                
                if time_quarter_index == -1:
                    continue
                    
                # Extract 4-line structure based on time_quarter position
                play_data = {
                    'play_summary': None,      # Line before time_quarter
                    'time_quarter': time_quarter_line,  # Line with time pattern  
                    'play_description': None,  # Line after time_quarter
                    'situation': None          # Optional 4th line
                }
                
                # Line 1: play_summary (before time_quarter)
                if time_quarter_index > 0:
                    play_data['play_summary'] = texts[time_quarter_index - 1]
                    
                # Line 3: play_description (after time_quarter)
                if time_quarter_index + 1 < len(texts):
                    play_data['play_description'] = texts[time_quarter_index + 1]
                    
                # Line 4: situation (optional down & distance)
                if time_quarter_index + 2 < len(texts):
                    potential_situation = texts[time_quarter_index + 2]
                    if re.search(r'\d+(st|nd|rd|th)\s*&\s*\d+', potential_situation):
                        play_data['situation'] = potential_situation
                
                if play_data['play_summary'] and play_data['time_quarter'] and play_data['play_description']:
                    plays_data.append(play_data)
                    
            return plays_data
            
        except Exception as e:
            print(f"   âŒ Error parsing 4-line structure: {e}")
            return []
    
    def extract_structured_fields(self, play_data):
        """Extract structured fields from 4-line play data"""
        structured = {
            'quarter': None,
            'time_remaining': None,
            'down': None,
            'distance': None,
            'yards_gained': None,
            'play_type': None
        }
        
        try:
            # Parse time_quarter: "8:53 - 3rd"
            if play_data['time_quarter']:
                time_match = re.match(r'(\d{1,2}:\d{2})\s*-\s*(1st|2nd|3rd|4th|OT)', play_data['time_quarter'])
                if time_match:
                    structured['time_remaining'] = time_match.group(1) + ':00'
                    
                    quarter_text = time_match.group(2).lower()
                    quarter_map = {'1st': 1, '2nd': 2, '3rd': 3, '4th': 4, 'ot': 5}
                    structured['quarter'] = quarter_map.get(quarter_text)
            
            # Parse play_summary: "2-yd Run", "13-yd Pass"
            if play_data['play_summary']:
                # Extract yards
                yard_match = re.search(r'(\d+)-?yd', play_data['play_summary'])
                if yard_match:
                    structured['yards_gained'] = int(yard_match.group(1))
                
                # Extract play type
                summary_lower = play_data['play_summary'].lower()
                if 'run' in summary_lower:
                    structured['play_type'] = 'rush'
                elif 'pass' in summary_lower:
                    structured['play_type'] = 'pass'
                elif 'kick' in summary_lower:
                    structured['play_type'] = 'kickoff'
                elif 'punt' in summary_lower:
                    structured['play_type'] = 'punt'
                elif 'field goal' in summary_lower:
                    structured['play_type'] = 'field_goal'
            
            # Parse situation: "3rd & 2 at JAX 18"
            if play_data.get('situation'):
                down_dist_match = re.match(r'(\d+)(st|nd|rd|th)\s*&\s*(\d+)', play_data['situation'])
                if down_dist_match:
                    structured['down'] = int(down_dist_match.group(1))
                    structured['distance'] = int(down_dist_match.group(3))
                    
        except Exception as e:
            print(f"   âš ï¸ Error extracting structured data: {e}")
        
        return structured
    
    def save_plays_with_4_column_structure(self, plays_data, db_id):
        """Save plays with 4-column structure ADDED to existing columns"""
        if not plays_data:
            return 0
            
        cursor = self.conn.cursor()
        saved_count = 0
        
        try:
            for i, play_data in enumerate(plays_data, 1):
                structured = self.extract_structured_fields(play_data)
                
                # INSERT with ALL columns: existing + new 4-column structure
                cursor.execute("""
                    INSERT INTO plays (
                        game_id, play_sequence,
                        play_summary, time_quarter, play_description, situation,
                        quarter, time_remaining, down, distance, yards_gained, play_type,
                        play_number, yard_line
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                    )
                """, (
                    db_id,  # Use database ID for foreign key
                    i,
                    play_data['play_summary'],
                    play_data['time_quarter'],
                    play_data['play_description'], 
                    play_data.get('situation'),
                    structured['quarter'],
                    structured['time_remaining'],
                    structured['down'],
                    structured['distance'],
                    structured['yards_gained'],
                    structured['play_type'],
                    i,  # play_number (existing column)
                    None  # yard_line (existing column)
                ))
                saved_count += 1
                
            self.conn.commit()
            cursor.close()
            return saved_count
            
        except Exception as e:
            print(f"   âŒ Error saving plays: {e}")
            self.conn.rollback()
            cursor.close()
            return 0
    
    def get_mcp_browser_instructions(self, espn_url):
        """Get MCP browser automation instructions for ESPN scraping"""
        return {
            'url': espn_url,
            'steps': [
                f"Navigate to ESPN play-by-play page: {espn_url}",
                "Wait for page to load",
                "Find and expand all quarter accordions",
                "Extract play card data from sections",
                "Return structured play data as JSON"
            ],
            'javascript_functions': {
                'expand_accordions': """() => {
                    const accordions = document.querySelectorAll('[aria-expanded="false"]');
                    let expanded = 0;
                    accordions.forEach(accordion => {
                        if (accordion.textContent.includes('Quarter') || 
                            accordion.textContent.includes('1st') ||
                            accordion.textContent.includes('2nd') ||
                            accordion.textContent.includes('3rd') ||
                            accordion.textContent.includes('4th') ||
                            accordion.textContent.includes('OT')) {
                            accordion.click();
                            expanded++;
                        }
                    });
                    return expanded;
                }""",
                'extract_plays': """() => {
                    const plays = [];
                    const sections = document.querySelectorAll('section[data-testid*="prism"], section.Card');
                    
                    sections.forEach((section, index) => {
                        try {
                            const divs = section.querySelectorAll('div');
                            const texts = [];
                            
                            divs.forEach(div => {
                                const text = div.textContent?.trim();
                                if (text && text.length > 0) {
                                    texts.push(text);
                                }
                            });
                            
                            const allText = texts.join(' ');
                            if (/(\\d{1,2}:\\d{2}\\s*-\\s*(1st|2nd|3rd|4th|OT))/i.test(allText) &&
                                /(kick|pass|run|punt|yards|touchdown|penalty|sack|fumble|interception)/i.test(allText)) {
                                plays.push({
                                    index: index,
                                    texts: texts
                                });
                            }
                        } catch (e) {
                            console.log('Error processing section:', e);
                        }
                    });
                    
                    return { plays: plays };
                }"""
            }
        }
    
    def process_single_game_with_mcp(self, game_data):
        """Process single game - returns MCP instructions for actual browser automation"""
        
        db_id = game_data['db_id']
        espn_game_id = game_data['espn_game_id']
        home_team = game_data['home_team']
        away_team = game_data['away_team']
        
        print(f"\nğŸ¯ {away_team} @ {home_team}")
        print(f"   DB ID: {db_id}, ESPN ID: {espn_game_id} ({game_data['season']} Week {game_data['week']})")
        print(f"   Date: {game_data['date']}")
        
        espn_url = f"https://www.espn.com/nfl/playbyplay/_/gameId/{espn_game_id}"
        
        # Return MCP browser instructions
        mcp_instructions = self.get_mcp_browser_instructions(espn_url)
        mcp_instructions['game_data'] = game_data
        
        return mcp_instructions
    
    def process_mcp_browser_result(self, play_data_json, game_data):
        """Process the results from MCP browser automation"""
        
        print(f"   ğŸ“„ Processing MCP browser results...")
        
        # Parse the 4-line play structure
        plays_data = self.parse_4_line_play_structure(play_data_json)
        
        if not plays_data:
            print(f"   âŒ No valid play data extracted")
            return False
            
        print(f"   âœ… Extracted {len(plays_data)} plays with 4-line structure")
        
        # Show sample of first few plays
        for i, play in enumerate(plays_data[:3], 1):
            print(f"   ğŸ“‹ Play {i}: {play['play_summary']} | {play['time_quarter']}")
            
        # Save to database with 4-column structure ADDED to existing columns
        saved_count = self.save_plays_with_4_column_structure(plays_data, game_data['db_id'])
        
        if saved_count > 0:
            print(f"   âœ… SUCCESS: {len(plays_data)} plays extracted, {saved_count} saved to DB")
            return True
        else:
            print(f"   âŒ FAILED: Could not save plays to database")
            return False
    
    def run_mcp_scraper_demo(self, limit_games=3):
        """Run MCP scraper demo - shows instructions for first few games"""
        
        print("ğŸš€ MCP PLAYWRIGHT PLAY-BY-PLAY SCRAPER")
        print("=" * 60)
        print("âœ… Uses MCP Playwright browser tools (not ChromeDriver)")
        print("âœ… Adds 4-column structure to existing working columns")
        print("âœ… Processes ESPN play-by-play with correct DOM structure")
        
        games = self.get_all_games()
        
        if not games:
            print("âŒ No games found in database")
            return False
            
        print(f"\nğŸ¯ Found {len(games)} total games in database")
        print(f"ğŸ“‹ Processing first {limit_games} games to demonstrate MCP integration")
        
        for i, game in enumerate(games[:limit_games], 1):
            print(f"\n[{i}/{limit_games}] " + "=" * 40)
            
            mcp_instructions = self.process_single_game_with_mcp(game)
            
            print(f"   ğŸ“± ESPN URL: {mcp_instructions['url']}")
            print(f"   ğŸ”§ MCP Browser Instructions Ready:")
            for step in mcp_instructions['steps']:
                print(f"      â€¢ {step}")
                
            # This is where Claude Code MCP browser calls would execute
            print(f"   âš¡ Ready for MCP browser automation")
            print(f"   ğŸ’¾ Will save to database with 4-column structure")
            
            return mcp_instructions  # Return first game for actual processing
        
        return True

def main():
    """Main function"""
    
    print("ğŸ¯ MCP PLAYWRIGHT PLAY-BY-PLAY SCRAPER")
    print("=" * 50)
    print("ğŸš« NO MORE CHROMEDRIVER - Uses MCP Playwright")
    print("âœ… Adds 4-column structure to existing working columns")
    print("âœ… Processes all 465 games with real ESPN data")
    
    scraper = MCPPlayByPlayScraper()
    
    # Demo mode - show MCP integration for first game
    result = scraper.run_mcp_scraper_demo(limit_games=1)
    
    if isinstance(result, dict) and 'url' in result:
        print(f"\nğŸš€ READY FOR MCP BROWSER AUTOMATION")
        print(f"   ğŸ¯ First game prepared for browser extraction")
        print(f"   ğŸ“± ESPN URL: {result['url']}")
        print(f"   ğŸ”§ JavaScript functions ready for execution")
        
        print(f"\nğŸ“‹ NEXT STEPS:")
        print(f"   1. Claude Code executes MCP browser navigation")
        print(f"   2. Expand accordions with JavaScript")
        print(f"   3. Extract play data from ESPN DOM")
        print(f"   4. Parse 4-line play structure")
        print(f"   5. Save to database with existing + 4 new columns")
        
        return result
    else:
        print(f"\nâŒ Demo setup failed")
        return False

if __name__ == "__main__":
    result = main()
    if result:
        print(f"\nğŸ¯ MCP SCRAPER READY - Use with Claude Code MCP browser tools")